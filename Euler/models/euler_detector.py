import torch
from pytorch_metric_learning import losses
from pytorch_metric_learning.distances import CosineSimilarity, LpDistance
from .euler_interface import Euler_Encoder, Euler_Recurrent

import pandas as pd
import torch.nn.functional as F

import pickle
from sklearn.neighbors import LocalOutlierFactor
import tracemalloc

class DetectorEncoder(Euler_Encoder):
    '''
    Detector implimentation of Euler_Encoder interface
    '''

    def decode_all(self, zs, OUTPATH, unsqueeze=False):
        '''
        Given node embeddings, return edge likelihoods for
        all subgraphs held by this model
        For detector model, it's very simple. Just return the embeddings
        for ei[n] given zs[n]

        zs : torch.Tensor
            A T x d x N tensor of node embeddings generated by the models,
            it is safe to assume z[n] are the embeddings for nodes in the
            snapshot held by this model's TGraph at timestep n
        '''
        assert not zs.size(0) < self.module.data.T, \
            "%s was given fewer embeddings than it has time slices"\
            # % rpc.get_worker_info().name

        assert not zs.size(0) > self.module.data.T, \
            "%s was given more embeddings than it has time slices"\
            # % rpc.get_worker_info().name

        preds = []
        preds_temp = []
        ys = []
        cnts = []
        slices = []
        eis = []
        #lof_labels = []
        #lof_scores = []
        # print(self.module.data)
        preds2 = []
        print("decode_all: ", self.module.data.T, len(self.module.data.eis))
        # cpu_start_mem = tracemalloc.get_traced_memory()[0]
        # gpu_start_mem0 = torch.cuda.memory_allocated(device='cuda:0')
        # gpu_start_mem1 = torch.cuda.memory_allocated(device='cuda:1')
        # cpu_mems = []
        # gpu_mems0 = []
        # gpu_mems1 = []
        for i in range(self.module.data.T):
            # print(i, print(self.module.data.T))
            preds_i = self.decode(self.module.data.eis[i], zs[i], False)
            preds.append(preds_i.detach().cpu().numpy())
            preds_temp.append(preds_i.detach().cpu().numpy())
            ys.append(self.module.data.ys[i].detach().cpu().numpy())
            cnts.append(self.module.data.cnt[i].detach().cpu().numpy())
            slices.append(self.module.data.slices[i])
            eis.append(self.module.data.eis[i].detach().cpu().numpy())
            # if i==0:
            #     cpu_mems.append(tracemalloc.get_traced_memory()[0] - cpu_start_mem)
            #     gpu_mems0.append(torch.cuda.memory_allocated(device='cuda:0') - gpu_start_mem0)
            #     gpu_mems1.append(torch.cuda.memory_allocated(device='cuda:1') - gpu_start_mem1)
            # else:
            #     cpu_mems.append(tracemalloc.get_traced_memory()[0] - cpu_mems[-1])
            #     gpu_mems0.append(torch.cuda.memory_allocated(device='cuda:0') - gpu_mems0[-1])
            #     gpu_mems1.append(torch.cuda.memory_allocated(device='cuda:1') - gpu_mems1[-1])
            # TODO: perform LoF to get outlier score from the embeddings
            #lof_labels_i,lof_scores_i = self.lof(self.module.data.eis[i], zs[i], clf)
            #lof_labels.append(lof_labels_i)
            #lof_scores.append(lof_scores_i)
            # TODO: compute the neighborhood scores
            # preds2_i = self.get_src_score(self.module.data.eis[i], preds_i)
            # preds2.append(preds2_i)
        #print(rpc.get_worker_info().name + ' performing LoF on edge embeddings')
        # print(rpc.get_worker_info().name + ' saving predictions')
        # with open(OUTPATH + '_detect_alerts.pkl', 'wb') as f:
        #     pickle.dump(pd.DataFrame({'slices': slices, 'preds': preds_temp, 'ys': ys, 'cnts': cnts, 'eis': eis, 'preds2': preds2}), f)
        # with open(OUTPATH + 'client3.pkl', 'wb') as f:
        #     pickle.dump(pd.DataFrame({'slices': slices, 'ys': ys, 'cnts': cnts, 'eis': eis}), f)
        # exit()
        return preds, ys, cnts
    def score_edges(self, z, partition, nratio): # for validation
        '''
        Given a set of Z embeddings, returns likelihood scores for all known
        edges, and randomly sampled negative edges

        z : torch.Tensor
            A T x d x N tensor of node embeddings generated by the models,
            it is safe to assume z[n] are the embeddings for nodes in the
            snapshot held by this model's TGraph at timestep n
        partition : int
            An enum representing if this is training/validation/testing for
            generating negative edges
        nratio : float
            The model samples nratio * |E| negative edges for calculating loss
        '''
        n = self.module.data.get_negative_edges(partition, nratio)

        p_scores = []
        n_scores = []

        for i in range(len(z)):
            p = self.module.data.ei_masked(partition, i)
            if p.size(1) == 0:
                continue

            p_scores.append(self.decode(p, z[i], False))
            n_scores.append(self.decode(n[i], z[i], False))

        p_scores = torch.cat(p_scores, dim=0)
        n_scores = torch.cat(n_scores, dim=0)

        return p_scores, n_scores

    # def calc_contrastive_loss(self, z, labels, tau=0.1):
    def calc_loss_contrast(self, z, partition, nratio, device, tau=0.1):

        tot_loss = torch.zeros(1).to(device)
        ns = self.module.data.get_negative_edges(partition, nratio)
        closs_func = losses.ContrastiveLoss(pos_margin=1,neg_margin=0,distance=CosineSimilarity())

        for i in range(len(z)):
            ps = self.module.data.ei_masked(partition, i)
            if ps.size(1) == 0:
                continue

            # tot_loss += self.bce(postive.sum(dim=1), negative.sum(dim=1))
            tot_loss += self.bce(self.decode(ps, z[i], False), self.decode(ns[i], z[i], False))


            postive = self.decode_embed(ps, z[i], False)
            negative = self.decode_embed(ns[i], z[i], False)

            if torch.isnan(tot_loss).any():
                print("bce tot_loss: ", tot_loss)
                exit()
            # print(postive.shape)
            # print(negative.shape)
            # labels = torch.cat((torch.ones(postive.sum(dim=1).shape[0]), torch.zeros(negative.sum(dim=1).shape[0])), 0)
            # # print(labels.shape)
            # embeddings = torch.cat((postive, negative), 0)
            # # print(embeddings.shape)
            # closs = closs_func(embeddings, labels)
            # print(closs)
            # y = torch.zeros(negative.sum(dim=1).shape[0]).to(device)
            margin=1.0
            # Calculate cosine similarity
            sim = F.cosine_similarity(postive, negative)
            # if torch.isnan(sim).any():
            #     print("sim: ", sim)
            #     exit()
            # sim = torch.nan_to_num(sim)
            # print(sim)
            # Calculate the loss for positive and negative pairs
            # positive_loss = (1 - sim) ** 2
            # loss = F.relu(sim - margin) ** 2
            loss = (sim - margin) ** 2

            # print(negative_loss)
            # Combine the losses
            # loss = (1 - y) * negative_loss
            # if torch.isnan(loss).any():
            #     print("loss: ", loss)
            #     exit()

            closs = loss.sum()

            tot_loss += closs
        # print("final loss: ", tot_loss.true_divide(len(z)))
        if torch.isnan(tot_loss).any():
            print("tot_loss: ", tot_loss)
            exit()
        return tot_loss.true_divide(len(z))



    def calc_loss(self, z, partition, nratio, device):
        '''
        Sum up all of the loss per time step, then average it. For some reason
        this works better than running score edges on everything at once. It's better
        to run BCE per time step rather than all at once

        z : torch.Tensor
            A T x d x N tensor of node embeddings generated by the models,
            it is safe to assume z[n] are the embeddings for nodes in the
            snapshot held by this model's TGraph at timestep n
        partition : int
            An enum representing if this is training/validation/testing for
            generating negative edges
        nratio : float
            The model samples nratio * |E| negative edges for calculating loss
        '''
        tot_loss = torch.zeros(1).to(device)
        ns = self.module.data.get_negative_edges(partition, nratio)

        for i in range(len(z)):
            # print(torch.cuda.memory_allocated())
            # print(torch.cuda.max_memory_allocated())
            ps = self.module.data.ei_masked(partition, i)

            # Edge case. Prevents nan errors when not enough edges
            # only happens with very small timewindows
            if ps.size(1) == 0:
                continue

            # print(ps.shape)
            # t_index = torch.arange(0, ps.shape[1], dtype=torch.int64).to(device).detach()
            # pos_pred = self.decode(ps, z[i], False)
            # neg_pred = self.decode(ns[i], z[i], False)
            # print(t_index.shape)
            # prediction = torch.cat((self.decode(ps, z[i], False), self.decode(ns[i], z[i], False)), 0)

            # labels = torch.cat((torch.ones(self.decode(ps, z[i], False).shape[0]), torch.zeros(self.decode(ns[i], z[i], False).shape[0])), 0).to(self.module.device)
            # print(labels.shape)
            # print(i, z[i].shape, pos_pred.shape, neg_pred.shape)
            # print(torch.cuda.max_memory_allocated())

            # tot_loss += self.ap_loss(
            #     torch.cat((pos_pred, neg_pred), 0),
            #     torch.cat((torch.ones(pos_pred.shape[0]),torch.zeros(neg_pred.shape[0])), 0).to(self.module.device).detach(),
            #     t_index)
            # print(torch.cuda.max_memory_allocated())

            tot_loss += self.bce(
                self.decode(ps, z[i], False),
                self.decode(ns[i], z[i], False)
            )

            # tot_loss += self.sce_loss(
            #     self.decode(ps, z[i], False),
            #     self.decode(ns[i], z[i], False)
            # )

            # if i != 0:
            #     from torch_geometric.utils import to_dense_adj
            #     a = to_dense_adj(self.module.data.eis[i], max_num_nodes=self.num_nodes)[0]
            #     old_a = to_dense_adj(self.module.data.eis[i-1], max_num_nodes=self.num_nodes)[0]

            #     if torch.sum(torch.linalg.norm(a-old_a, dim=1,ord=2)).item() < 0.01:
            #         stable_loss = torch.sum(torch.linalg.norm(z[i]-z[i-1], dim=1,ord=2))/0.01
            #     else:
            #         stable_loss = torch.sum(torch.linalg.norm(z[i]-z[i-1], dim=1,ord=2))/torch.sum(torch.linalg.norm(a-old_a, dim=1,ord=2))
            #     # if torch.isinf(stable_loss):
            #     #     print(z[i])
            #     #     print(torch.sum(torch.linalg.norm(z[i]-z[i-1], dim=1,ord=2)))
            #     #     print(torch.sum(torch.linalg.norm(a-old_a, dim=1,ord=2)))
            #     #     print(stable_loss)
            #     tot_loss = tot_loss + 0.05 * stable_loss

        return tot_loss.true_divide(len(z))



    # xjc
    def calc_loss_argus(self, z, partition, nratio, device):
        tot_loss = torch.zeros(1).to(device)
        ns = self.module.data.get_negative_edges(partition, nratio)
        for i in range(len(z)):
            # print(torch.cuda.memory_allocated())
            # print(torch.cuda.max_memory_allocated())
            ps = self.module.data.ei_masked(partition, i)
            # Edge case. Prevents nan errors when not enough edges
            # only happens with very small timewindows
            if ps.size(1) == 0:
                continue

            # print(ps.shape)
            t_index = torch.arange(0, ps.shape[1], dtype=torch.int64).to(device).detach()
            pos_pred = self.decode(ps, z[i], False)
            neg_pred = self.decode(ns[i], z[i], False)
            # print(t_index.shape)
            # prediction = torch.cat((self.decode(ps, z[i], False), self.decode(ns[i], z[i], False)), 0)

            # labels = torch.cat((torch.ones(self.decode(ps, z[i], False).shape[0]), torch.zeros(self.decode(ns[i], z[i], False).shape[0])), 0).to(self.module.device)
            # print(labels.shape)
            # print(i, z[i].shape, pos_pred.shape, neg_pred.shape)
            # print(torch.cuda.max_memory_allocated())

            tot_loss += self.ap_loss(
                torch.cat((pos_pred, neg_pred), 0),
                torch.cat((torch.ones(pos_pred.shape[0]),torch.zeros(neg_pred.shape[0])), 0).to(self.module.device).detach(),
                t_index)
            # print(torch.cuda.max_memory_allocated())
            # tot_loss += 0.0001 * self.bce(
            #     self.decode_back(ps, z[i], False),
            #     self.decode_back(ns[i], z[i], False)
            # )

            # if i != 0:
            if i != 0 and 1 == 0:
                from torch_geometric.utils import to_dense_adj
                a = to_dense_adj(self.module.data.eis[i], max_num_nodes=self.num_nodes)[0]
                old_a = to_dense_adj(self.module.data.eis[i-1], max_num_nodes=self.num_nodes)[0]

                if torch.sum(torch.linalg.norm(a-old_a, dim=1,ord=2)).item() < 0.01:
                    stable_loss = torch.sum(torch.linalg.norm(z[i]-z[i-1], dim=1,ord=2))/0.01
                else:
                    stable_loss = torch.sum(torch.linalg.norm(z[i]-z[i-1], dim=1,ord=2))/torch.sum(torch.linalg.norm(a-old_a, dim=1,ord=2))
                tot_loss = tot_loss + 0.05 * stable_loss
        return tot_loss.true_divide(len(z))


class DetectorRecurrent(Euler_Recurrent):
    def score_all(self, zs, OUTPATH, unsqueeze=False):
        '''
        Has the distributed models score and label all of their edges
        Sends workers embeddings such that zs[n] is used to reconstruct graph at
        snapshot n

        zs : torch.Tensor
            A T x d x N tensor of node embeddings generated by each graph snapshot
            Need to offset according to how far in the future embeddings are supposed
            to represent.
        '''
        futs = []
        futs = DetectorEncoder.decode_all(self.gcns, zs, OUTPATH, unsqueeze)

        obj = [futs] #[f.wait() for f in futs]
        scores, ys, cnts = zip(*obj)

        # Compress into single list of snapshots
        scores = sum(scores, [])
        ys = sum(ys, [])
        cnts = sum(cnts, [])

        return scores, ys, cnts


    def loss_fn(self, zs, partition, nratio=1, device=None, encoder_name=None):
        '''
        Runs NLL on each worker machine given the generated embeds
        Sends workers embeddings such that zs[n] is used to reconstruct graph at
        snapshot n

        zs : torch.Tensor
            A T x d x N tensor of node embeddings generated by each graph snapshot
            Need to offset according to how far in the future embeddings are supposed
            to represent.
        partition : int
            enum representing train, validation, test sent to workers
        nratio : float
            The workers sample nratio * |E| negative edges for calculating loss
        '''
        futs = []
        start = 0
        # print(encoder_name)
        if encoder_name == 'ARGUS':
            futs = DetectorEncoder.calc_loss(self.gcns, zs, partition, nratio, device)
            # futs = DetectorEncoder.calc_loss_argus(self.gcns, zs, partition, nratio, device)

        else:
            futs = DetectorEncoder.calc_loss(self.gcns, zs, partition, nratio, device)

        tot_loss = torch.zeros(1).to(device)

        for f in futs:
            tot_loss += f

        return tot_loss


    def score_edges(self, zs, partition, nratio=1):
        '''
        Gets edge scores from dist modules, and negative edges.
        Sends workers embeddings such that zs[n] is used to reconstruct graph at
        snapshot n

        zs : torch.Tensor
            A T x d x N tensor of node embeddings generated by each graph snapshot
            Need to offset according to how far in the future embeddings are supposed
            to represent.
        partition : int
            enum representing train, validation, test sent to workers
        nratio : float
            The workers sample nratio * |E| negative edges for calculating loss
        '''
        futs = []
        futs = DetectorEncoder.score_edges(self.gcns, zs, partition, nratio)
        # print(futs)
        pos, neg = zip(*[futs])
        return torch.cat(pos, dim=0), torch.cat(neg, dim=0)
